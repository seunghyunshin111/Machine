## 회귀

- Loss function이 낮은 값이 좋은 값
- Gradient Descent 선형 회귀 외에도 여러 방식에 많이 사용 됨

<br>

## 선형 회귀

- 직선 -> 곡선으로 하면 더 잘 피팅되지 않을까?=> 다중 선형 회귀 -> 다항 선형 회귀!
- 다항 회귀는 과적합 문제 발생 가능
- 과적합 해결을 위해 정규화 과정 으로 보완
- 과적합 해결을 위해 교차 검증 으로 보완

<br>

## 정규화

- 불필요한 베타값을(->0) 줄여, 곡선->직선 방식으로 정규화



<br>

## 	분류

- 로지스틱 회귀: 0, 1 이진 분류에 적합
- SVM: 딥러닝 기술이 암흑기에 있었을 때, 선풍적으로 인기 끌었던 것.
- SVM: 수학적으로 최적화 과정이 굉장히 깔끔, 이론적으로 푸는 방식은 조금 어려움

<br>

## SVM

- max(Margin(b1, b2))
- Soft margin을 허용\

<br>

## GMM

- 개별 데이터가 어떤 정규 분포에 속하는지 결정해야 함
- 중심에 해당되는 것이 평균과 분산

<br>

## RSS

- 단순한데, 성능 좋음